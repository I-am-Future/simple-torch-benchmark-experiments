2024-01-21 07:24:01,714 - root - INFO - Initializing configs...
2024-01-21 07:24:01,714 - root - INFO - The configs are: {'work_dir': '.', 'device': 'cuda:0', 'batch_size': 16, 'num_workers': 2, 'train_ratio': 0.7, 'optimizer_config': {'lr': 0.0005}, 'scheduler_config': {'T_max': 100, 'eta_min': 5e-05, 'last_epoch': -1, 'warmup_steps': 5, 'warmup_start_lr': 1e-05}, 'total_epoch': 15, 'glove_name': '6B', 'glove_dim': 200, 'model_config': {'hidden_units': 200, 'num_layers': 8, 'dropout_rate': 0.25}, 'enable_tb': False}
2024-01-21 07:24:01,715 - torchtext.vocab - INFO - Downloading vectors from http://nlp.stanford.edu/data/glove.6B.zip
2024-01-21 07:28:08,885 - torchtext.vocab - INFO - Extracting vectors into .vector_cache
2024-01-21 07:28:25,715 - torchtext.vocab - INFO - Loading vectors from .vector_cache/glove.6B.200d.txt
2024-01-21 07:29:03,796 - torchtext.vocab - INFO - Saving vectors to .vector_cache/glove.6B.200d.txt.pt
2024-01-21 07:29:10,711 - root - INFO - Total parameters: 7864585
2024-01-21 07:29:10,711 - root - INFO - Begin training now...
2024-01-21 07:29:28,448 - root - INFO - epoch 1/15, duration=17.028375s train_loss=0.7070, train_acc=0.5339, val_loss=0.6825, val_acc=0.5841, saving model.
2024-01-21 07:29:42,655 - root - INFO - epoch 2/15, duration=14.20529s train_loss=0.6889, train_acc=0.5600, val_loss=0.6812, val_acc=0.5841, 
2024-01-21 07:29:55,500 - root - INFO - epoch 3/15, duration=12.844613s train_loss=0.6871, train_acc=0.5645, val_loss=0.6833, val_acc=0.5841, 
2024-01-21 07:30:08,651 - root - INFO - epoch 4/15, duration=13.149644s train_loss=0.6906, train_acc=0.5553, val_loss=0.6803, val_acc=0.5841, 
2024-01-21 07:30:21,522 - root - INFO - epoch 5/15, duration=12.86931s train_loss=0.6900, train_acc=0.5579, val_loss=0.6806, val_acc=0.5841, 
2024-01-21 07:30:36,310 - root - INFO - epoch 6/15, duration=14.78674s train_loss=0.6926, train_acc=0.5577, val_loss=0.6829, val_acc=0.5841, 
2024-01-21 07:30:51,072 - root - INFO - epoch 7/15, duration=14.760831s train_loss=0.6985, train_acc=0.5408, val_loss=0.6926, val_acc=0.5841, 
2024-01-21 07:31:06,234 - root - INFO - epoch 8/15, duration=15.161388s train_loss=0.6907, train_acc=0.5566, val_loss=0.6852, val_acc=0.5841, 
2024-01-21 07:31:19,403 - root - INFO - epoch 9/15, duration=13.167833s train_loss=0.6902, train_acc=0.5540, val_loss=0.6982, val_acc=0.4159, 
2024-01-21 07:31:33,700 - root - INFO - epoch 10/15, duration=14.296521s train_loss=0.6894, train_acc=0.5573, val_loss=0.6816, val_acc=0.5841, 
2024-01-21 07:31:48,313 - root - INFO - epoch 11/15, duration=14.611485s train_loss=0.6893, train_acc=0.5577, val_loss=0.6808, val_acc=0.5841, 
2024-01-21 07:32:02,408 - root - INFO - epoch 12/15, duration=14.094109s train_loss=0.6889, train_acc=0.5639, val_loss=0.6804, val_acc=0.5841, 
2024-01-21 07:32:17,668 - root - INFO - epoch 13/15, duration=15.259086s train_loss=0.6897, train_acc=0.5648, val_loss=0.6824, val_acc=0.5841, 
2024-01-21 07:32:33,016 - root - INFO - epoch 14/15, duration=15.346577s train_loss=0.6882, train_acc=0.5592, val_loss=0.6815, val_acc=0.5841, 
2024-01-21 07:32:46,878 - root - INFO - epoch 15/15, duration=13.86166s train_loss=0.6888, train_acc=0.5631, val_loss=0.6811, val_acc=0.5841, 
